{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "005018ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy \n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aca873",
   "metadata": {},
   "source": [
    "##### instead of words keras imdb it has a dictionary of whole corpus with frequency of words than sorted based on dictionary and given index value\n",
    "\n",
    "#### Refer: https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c00f8482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_words` argument in `load_data` has been renamed `num_words`.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Refer: https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification\n",
    "\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a80352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
      "type   : <class 'list'>\n",
      "length   : 189\n"
     ]
    }
   ],
   "source": [
    "#here is the vector representation of first sentence\n",
    "print(X_train[1])\n",
    "print(\"type   :\",type(X_train[1]))\n",
    "print(\"length   :\",len(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76e9df71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0ed6ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(numpy.max(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0e50dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9eb3f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 600)\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    1  194 1153  194    2   78  228    5    6\n",
      " 1463 4369    2  134   26    4  715    8  118 1634   14  394   20   13\n",
      "  119  954  189  102    5  207  110 3103   21   14   69  188    8   30\n",
      "   23    7    4  249  126   93    4  114    9 2300 1523    5  647    4\n",
      "  116    9   35    2    4  229    9  340 1322    4  118    9    4  130\n",
      " 4901   19    4 1002    5   89   29  952   46   37    4  455    9   45\n",
      "   43   38 1543 1905  398    4 1649   26    2    5  163   11 3215    2\n",
      "    4 1153    9  194  775    7    2    2  349 2637  148  605    2    2\n",
      "   15  123  125   68    2    2   15  349  165 4362   98    5    4  228\n",
      "    9   43    2 1157   15  299  120    5  120  174   11  220  175  136\n",
      "   50    9 4373  228    2    5    2  656  245 2350    5    4    2  131\n",
      "  152  491   18    2   32    2 1212   14    9    6  371   78   22  625\n",
      "   64 1382    9    8  168  145   23    4 1690   15   16    4 1355    5\n",
      "   28    6   52  154  462   33   89   78  285   16  145   95]\n"
     ]
    }
   ],
   "source": [
    "# truncate and/or pad input sequences\n",
    "#padding here convert each sentence into sequence of 600 words. It adds zero before sequence to make its length 600 if \n",
    "#number of words less than 600 if greater than just simply discards\n",
    "max_review_length = 600\n",
    "X_train = keras.utils.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = keras.utils.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95415274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24628a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 600, 32)           160000    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               53200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dceb9476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 183s 464ms/step - loss: 0.4779 - accuracy: 0.7665\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 182s 467ms/step - loss: 0.2929 - accuracy: 0.8818\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 187s 479ms/step - loss: 0.2496 - accuracy: 0.9030\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 184s 471ms/step - loss: 0.2177 - accuracy: 0.9163\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 7128s 18s/step - loss: 0.2057 - accuracy: 0.9206\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 189s 482ms/step - loss: 0.1791 - accuracy: 0.9314\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 191s 488ms/step - loss: 0.1655 - accuracy: 0.9374\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 195s 499ms/step - loss: 0.1376 - accuracy: 0.9479\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 192s 490ms/step - loss: 0.1419 - accuracy: 0.9470\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 190s 486ms/step - loss: 0.1277 - accuracy: 0.9533\n",
      "Accuracy: 86.17%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=64)\n",
    "# Final evaluation of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "788c85b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 38s 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01236876],\n",
       "       [0.9997832 ],\n",
       "       [0.08457205],\n",
       "       ...,\n",
       "       [0.05396811],\n",
       "       [0.10815634],\n",
       "       [0.99788207]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21d2f039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.17%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa15acd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
